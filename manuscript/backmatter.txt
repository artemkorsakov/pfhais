{backmatter}

# Epilogue #

Q> So what have we gained from this?

I personally hope that you had some fun reading this, have learned something and got some ideas about what is possible in the realm of programming. For me it was fun to write this book and I also learned a lot while writing it. I want to thank all the people that got back to me with questions, hints and ideas about what might be missing.

The next time some person points out that all this "academic functional nonsense" is for naught please remember some of the things you read here. We have seen several things that imply that we can use pure functional programming in our daily work:

1. better understandable code
2. better testable code
3. better performing code (Yes!)
4. better type safety using refined types
5. deriving boilerplate code from our statically typed models and logic
6. easier working with deeply nested structures using optics

There really is no excuse to stick to impure and messy stuff that is hard to maintain. But please remember also that functional programming is not done for the sake of itself. It is another and in my opinion better way to deliver value. In our field of work this (*value*) usually means some working software / program / application / whatever.

Also please do not consider this book a complete knowledge trove. Several things might already be outdated, some topics have only been scratched on the surface and other things are missing completely.

So, people of the baud and the electron: Go out there, venture forth, cross boundaries, use the knowledge which is there and last but not least - Have fun!

## Moving to Scala 3...

When I wrote this book version 2.12 was the thing and 2.13 was not yet released. While I did enable cross-building for 2.13 after it was released the next big version was still far away. But then it happened and Scala 3 was released. However it took some time until libraries and frameworks moved to support it. As I am writing this some still have not added support for it because in some areas this involves a significant amount of work.

However, I always wanted to do an update to Scala 3 and while I might still find time to write a complete book about that, I chose not to wait longer although some libraries I would like to use are still not ported. Therefore the topic of this chapter will be to update our small service (the tapir version) to Scala 3 while dropping some not yet ported libraries.

But instead of jumping right into the middle of it we might be better of to look at our options and plan our migration accordingly.

The first step should be to switch to Scala 2.13 as major version and update all dependencies to their latest versions. This alone will be quite some work but it will ease the migration to Scala 3 for which we will try to use some tools which are available.

Since version 1.5 the sbt build tool supports Scala 3 directly so there is no more need to add the sbt-dotty plugin to your build. Additionally it supports a new syntax for dependencies which will allow us to use 2.13 libraries in 3 and vice versa.

```
libraryDependency +=
  ("my.domain" %% "my-lib" % "x.y.z").cross(CrossVersion.for3Use2_13)
```

The example above instructs sbt to use a Scala 2.13 library for Scala 3. If you want to do the opposite then you have to use `CrossVersion.for2_13Use3` instead which will make sbt use a Scala 3 library for Scala 2.13.

Furthermore there is the Scala-3-Migrate plugin for sbt which supports on a variety of topics when migration a project to Scala 3.

So the second step would be to use the Scala-3-Migrate plugin to guide our migration to Scala 3. During this phase we will see what can be kept, what can be used with some restrictions and what has to be dropped.

### Step 1: Updating to 2.13.x

The currently recommended version to start a migration from is 2.13.7 so we will target this Scala version for updating our project. In the source code you can see that I simply copied the `tapir` folder of our project and named it `tapir-scala-3` to not mess with our existing code.

First steps include updating sbt to a recent version as well as updating the sbt-plugins that we are using to their latest versions. Also some changes are made in regard to the compiler plugins. The kind-projector plugin needs a different way to be specififed (see `cross CrossVersion.full` in `build.sbt`) and the monadic-for plugin stays for now but will have to be removed when we're on Scala 3. And while at it the migration plugin to support us is added as well:

```
addSbtPlugin("ch.epfl.scala" % "sbt-scala3-migrate" % "0.5.0")
```

Now we switch the default version for Scala to `2.13.7` and try to compile the project. We run into some missing dependencies errors which will force our hand into upgrading several dependencies. In addition we stumble upon the matter that the compiler flag `-Xlint:nullary-override` has been dropped so we remove it or comment it out.

I> As much as I like it to turn any warning into an error, for a migration like this I recommend to fix only the deprecation issues and then turn of the `Xfatal-warnings` flag.

Furthermore to reduce the clutter in our build file we remove support for Scala 2.12 and the related compiler options. In the case that you have to support older versions of Scala (cross compilation) things get more complicated. In our case we can move completely to Scala 3. :-)

#### Details and some compiling issues

So what was done until now?

1. include kind-projector plugin via CrossVersion.full
2. switch to Scala 2.13.7 aus default version
3. remove Scala 2.12 and related settings
4. update doobie to 0.8.8
5. update http4s to 0.21.31
6. update tapir to 0.11.11
7. update circe to 0.14.1
8. remove dropped compiler flags (for 2.13!)
9. disable `Xfatal-warnings`

So far compiling our main code resulted in nagging us to fix several issues with auto-application of missing brackets for function calls, the main culprit being `unsafeRunSync` here which has to be `unsafeRunSync()`. Also some unused variable issues were popping up and are fixed easily too.

Now onwards to compiling the tests and we have some more issues. So far the integration tests compile fine but the unit tests spill out an error:

```txt
[error] .../TestRepository.scala:26:51: trait Seq takes type parameters
[error]         val ns = p.names.toNonEmptyList.toList.to[Seq]
[error]                                                   ^
[error] .../TestRepository.scala:26:50: missing argument list for method to in trait IterableOnceOps
[error] Unapplied methods are only converted to functions when a function type is expected.
[error] You can make this conversion explicit by writing `to _` or `to(_)` instead of `to`.
[error]         val ns = p.names.toNonEmptyList.toList.to[Seq]
[error]                                                  ^
[error] .../TestRepository.scala:32:49: trait Seq takes type parameters
[error]       val ns = p.names.toNonEmptyList.toList.to[Seq]
[error]                                                 ^
[error] .../TestRepository.scala:32:48: missing argument list for method to in trait IterableOnceOps
[error] Unapplied methods are only converted to functions when a function type is expected.
[error] You can make this conversion explicit by writing `to _` or `to(_)` instead of `to`.
[error]       val ns = p.names.toNonEmptyList.toList.to[Seq]
[error]                                                ^
[error] four errors found
```

This looks big at first but let us stay calm an read the error messages. So the "trait Seq takes takes type parameters" eh? The second one says something about "unapplied methods" but isn't exactly helpful either.

Q> What can we do?

Well, we fire up a REPL of course and as we are (or should be) in sbt we can simply use the `console` command. This will only work if we fixed all our compilation errors in the main code.

```scala
scala> List(1, 2, 3).to<TAB>
// This should show a list of possible functions.
```

So it seems we are missing our plain old (`.to[T]`). While there is a `.to()` function it requires a collection factory. So what about `.toSeq`? We did not use it in the past because it converted into a mutable sequence. But what about now?

```scala
scala> val a: scala.collection.immutable.Seq[Int] = List(1, 2, 3).toSeq
val a: Seq[Int] = List(1, 2, 3)
scala> a.getClass
val res0: Class[_ <: Seq[Int]] = class scala.collection.immutable.$colon$colon

scala> a.getClass.getCanonicalName
val res1: String = scala.collection.immutable.$colon$colon

scala> a.getClass.getName
val res2: String = scala.collection.immutable.$colon$colon
```

Well, well this looks pretty good I'd say so let's adjust the code. And quickly we get a big type error but the gist of it is:

```txt
[error] Note: List[...] <: Seq[...], but type F is invariant in type _.
[error] You may wish to define _$$1 as +_$$1 instead. (SLS 4.5)
[error]         ns.map(n => (p.id, n.lang, n.name)).pure[F]
[error]                                                 ^
[error] one error found
```

Good news first: The original error is gone and we can even simplify the code around the second error source by removing the `toSeq` completely. But the remaining one is heavier. So let's take a step back and take a deep breathe. If we take a look at our function signature we can see that it requires a `Seq` but what if we simply change it to `List`?

So let us try it and see how far we get. First we have to change the type signature of the function `loadProduct` in `Repository` to have a `List` instead of a `Seq` in its return type. Afterwards the compiler will tell us exactly in which places we have to make changes. Furthermore we can also remove some imports (`scala.collection.immutable.Seq`) which are no longer needed.

Okay, onwards to... Did you run the tests? ;-)

While executing the tests we discover that some unit tests are failing and the integration tests look good. Additionally I get a warning that the Flyway library should be updated. But we save this for later. Let us take a look at our failing tests first. We can see that they error out because of an exception:

```txt
java.lang.NoSuchMethodError: 'cats.data.Kleisli
  org.http4s.HttpRoutes$.apply(scala.Function1, cats.effect.Sync)'
```

This does not look good and it seems to be not caught by the compiler. We should start our service to see if it happens there too. So after a `sbt run` we can see that it affects our main code also.

Nice we just broke our service. Welcome to the world of software development! :-)

Q> So what could be the root cause here?

Most likely we are in trouble due to updating dependencies and running into some binary incompatibility issues. The error message indicates that it might either be cats or http4s related. To get some more insights we should issue the `sbt evicted` command and take a look at the output. We find some messages about replaced versions.

```txt
* org.http4s:http4s-dsl_2.13:0.21.31 is selected over 0.21.0-M5
...
* org.typelevel:cats-effect_2.13:2.5.1 is selected over {2.0.0, ...}
...
* org.typelevel:cats-core_2.13:2.6.1 is selected over {2.0.0, ...}
...
* org.http4s:http4s-blaze-server_2.13:0.21.31 is selected over 0.21.0-M5
...
```

Now we need to perform some investigations regarding the libraries which means digging into changelog entries, release notes and bug reports which might support our idea of something was broken. The cats part of the equation looks fine but there were some changes in the http4s library which might be the cause for our problem here. As the older version (`0.21.0-M5`) is a pre-release this is something that is totally valid and should always be on our radar. The older version is a dependency of tapir so that means we have to upgrade tapir as well which means "More breaking changes, yeah!" ;-)

I> The more you run into problems when updating your applications the more you come to understand the restraint to updates. But if your application is still actively maintained then updates are a part of life and regular updates save you the pain of doing a major one every couple of years.

But before we tackle this problem we might as well quickly update the Flyway library to get rid of the warning in our tests. Brave as we are we jump to the most recent release and also update the driver for PostgreSQL as well. But what is this?

```txt
[error] .../FlywayDatabaseMigrator.scala:35:21: type mismatch;
[error]  found   : org.flywaydb.core.api.output.MigrateResult
[error]  required: Int
[error]       flyway.migrate()
[error]                     ^
[info] org.flywaydb.core.api.output.MigrateResult <: Int?
[info] false
[error] one error found
```

You didn't expect this to be easy, did you? ;-) But this doesn't look like a big issue. The return type of the migrate function was changed upstream and the only decision we have to make is if we want to change our function return type accordingly and simply pass the information onwards or de we change the function a bit and still only return the number of applied migrations. I pick the lazy route this time and simply append `.migrationsExecuted` to the call to `.migrate()` and we're done with it.

Now onwards to our tapir update. Before we simply upgrade to the latest version we should give it some more thought. Tapir is still in a heavy development phase and might depend on pre-release versions of other libraries again. So we better look some things up. The file `project/Versions.scala` within the tapir source repository gives us our needed insights. If we do not want to upgrade http4s even higher then it seem we will have to pick a tapir 0.17.x release. Such a jump will likely include lots of breaking changes so another option would be to pick the lowest possible tapir release with a compatible http4s dependency.

Q> So what are our options?

We can either upgrade to the highest tapir version with a still compatible http4s dependency. Or we try to do the "minimum viable upgrade" and pick the lowest possible tapir version with a compatible http4s dependency to reduce our changes to a minimum. Last but not least we have the option to upgrade to the latest tapir version and upgrade all other dependencies as well.

The last option might be tempting but it will force us to upgrade not only http4s but other dependencies as well and we will likely head straight into "upgrade dependency hell" and may not even succeed.

Of our other options we can pick either the version 0.17.20 or something from the 0.12.x line of the tapir releases. Please not that the artefact organization name for tapir has changed! If you simply change the version number you will get unresolved dependency errors.

Upgrading software is not for the faint hearted so let's be brave and try to update to 0.17.20. The line between bravery and stupidity is a bit hazy but we'll see how we do. :-)

The first thing we stumble upon is of course a ton of errors because the namespace for tapir changed. Because changing it is simple but tedious it screams for automation and therefore we'll use a shell script.

```sh
% for i in `find tapir-scala-3 -name "*.scala"`; do
%   sed -i '' -e s/'import tapir'/'import sttp.tapir'/g $i
% done
```

This script is specific to the `sed` version used in the BSD operating systems! It is a simple loop being fed from a `find` command and uses `sed` to perform a search and replace operation directly in the file. The `-i ''` parameter ensures that no backup is saved (We are within in version control anyway.).

Okay after fixing that and the change of `StatusCode` and `StatusCodes` from tapir to sttp we still get a log of errors which look quite intimidating. Deciding that bravery is all good and so we turn to plan B switching the tapir version to 0.12.28. ;-)

We still get a bunch of errors now but they are less in number and seem mostly related to schema creation and derivation. Also not the most easy topic but as we get the same errors on 0.17.x plus a load more we might as well try to fix them. The first guess is that some code has been moved and indeed it seems that our `Schema.SWhatever` types are now under `SchemaType.SWhatever` so this should be fixed easily. Additionally we need to do small adjustments regarding changed signatures and use `Schema(SchemaType.SWhatever)` instead of `Schema.SWhatever` in some places.

```txt
...
[warn] two warnings found
[error] 6 errors found
```

Nice! We are down to a single digit number of errors. It looks like I didn't fix the `StatusCodes` issue correctly so after some changes we are down to one error:

```txt
[error] .../ProductsRoutes.scala:117:54: not found: value tapir
[error] streamBody[Stream[F, Byte]](schemaFor[Byte], tapir.MediaType.Json())
[error]                                              ^
[error] one error found
```

After digging a bit through the tapir code we can see that we simply have to pass a `CodecFormat.Json()` here now. Hooray, it compiles! But before we become too confident, let us run some tests.

```txt
[info] All tests passed.
```

This is good news and furthermore starting our service via `sbt run` looks good also. :-)

Now we could move on to the next step or we might try updating some more dependencies. For starters we remove the wartremover plugin because it isn't available for Scala 3 anyway. Besides the plugin we must remove the settings in the `build.sbt` and the annotations within the code (see the `@SuppressWarnings` annotations). As a bonus we get rid of some warnings about `Any` type inference which are false positives anyway. Next is the move to the Ember server for http4s from the Blaze one because Ember is the new default and recommended one. For this the our main entry point in `Tapir.scala` has to be adjusted a bit.

First we change from `IOApp` to `IOApp.WithContext` and implement the `executionContextResource` function. In addition we adjust our blocking thread pool to use 2 threads or half of the available processors.

```scala
object Tapir extends IOApp.WithContext {
  val availableProcessors: Int =
    Runtime.getRuntime().availableProcessors() / 2
  val blockingCores: Int =
    if (availableProcessors < 2) 2 else availableProcessors
  val blockingPool: ExecutorService =
    Executors.newFixedThreadPool(blockingCores)
  val ec: ExecutionContext =
    ExecutionContext.global

  override protected def executionContextResource: 
    Resource[SyncIO, ExecutionContext] = Resource.eval(SyncIO(ec))

  def run(args: List[String]): IO[ExitCode] = {
    val blocker = Blocker.liftExecutorService(blockingPool)
    val migrator: DatabaseMigrator[IO] = new FlywayDatabaseMigrator
    // ...
      resource = EmberServerBuilder
        .default[IO]
        .withBlocker(blocker)
        .withHost(apiConfig.host)
        .withPort(apiConfig.port)
        .withHttpApp(httpApp)
        .build
      fiber = resource.use(_ => IO(StdIn.readLine())).as(ExitCode.Success)
    // ...
```

W> Please beware that the `availableProcessors` function might report wrong values if the JVM is running within a docker container!

The update of the refined library requires us to update pureconfig as well in one step but it just works after increasing the version numbers. The same can be said about logback, cats and kittens. For the latter we make some small adjustment to get rid of a deprecation warning.

Some more changes are required for updating ScalaTest and ScalaCheck but they boil down to changing some imports and names (i.e. `Matchers` instead of `MustMatchers`) and the inclusion of the ScalaTestPlus library which acts as a bridge to ScalaCheck now.

I> Note that we run tests and integration tests after each dependency update to be sure!

The things left to update look like they might be a bit more involving:

1. Doobie (database layer)
2. http4s (might not be that difficult as we switched to Ember already)
3. Monocle (version 3.x brings huge improvements but will require many changes)
4. tapir (contains breaking changes and might introduce more dependency trouble)

As mentioned before we shouldn't simply dive in but check what is really needed. To gather the necessary information we move on to the next step.

### Step 2: Migrating to Scala 3

We have prepared our battle ground and already included the sbt plugin so we can just issue the `migrate-libs tapir` command to get some output. This is quite a lot so let's concentrate on the important parts. First there is some explanation on the top:

```txt
[info] X             : Cannot be updated to scala 3
[info] Valid         : Already a valid version for Scala 3
[info] To be updated : Need to be updated to the following version
```

We should not see the `X` mark (usually red in the terminal) but here we are and I count two of them. So what do we have?

1. The better-monadic-for plugin.
2. The pureconfig library.

The first one is no problem because we can simply drop it and the underlying problem is supposed to be solved in Scala 3. But what about pureconfig? Well let's worry later and process the output further. We have quite some `Valid` marks which is great! Several others have other notes on them so onward to take a closer look.

The following dependencies are supposed to work with `CrossVersion.for3Use2_13`:

1. Monocle
2. Refined

Last but not least some dependencies need to be updated further to support Scala 3:

1. Doobie
2. http4s
3. kittens
4. tapir

So it looks like we won't get away without doing major upgrades anyway. While at it we might as well add Monocle to our upgrade list because it looks like it will be quite some work either way.

The attentive reader will have noted that the recommended dependency updates have pre-release version numbers and she'll ask if we really should upgrade them or wait until proper releases have been published. And yes, she is right: Though shall not use pre-release software in production!

For our example here however we do it for demonstrating the upgrade process. In production I would advise you to wait or maybe upgrade and test in a separate environment.

Q> But where to start?

"Oh what tangled web we weave when our deps are transitive!" -- With apologies to Sir Walter Scott

So, tapir has dependencies on http4s and also cats-effect it will surely influence http4s and also doobie which also uses cats-effect. So the first candidate should be kittens because it doesn't affect the other dependencies. The next one will be Monocle because although *maybe* not necessary it also doesn't mess up the other dependencies. While updating kittens is done by simply increasing the version number the Monocle part will likely be more involving. After increasing the version number for Monocle and changing also the artefact group and removing the laws package we are greeted by a number of deprecation warnings and one errors upon compilation. This doesn't look too bad so maybe we are lucky after all, are we?

For the deprecations there is an open issue for providing Scalafix rules for automatic code rewrite but it is not yet done[^41] therefore we have to do it ourselves. But at the issue we find a nice list of deprecated methods and their replacements! As for the error message:

```txt
[error] .../Tapir.scala:117:11: object creation impossible.
        Missing implementation for:
[error]   def modifyA[F[_]](f: V => F[V])
            (s: scala.collection.immutable.ListMap[K,V])
            (implicit evidence$1: cats.Applicative[F]):
            F[scala.collection.immutable.ListMap[K,V]]
            // inherited from trait PTraversal
[error]       new Traversal[ListMap[K, V], V] {
[error]           ^
```

This might look intimidating but actually it is just complaining about a missing implementation so we will have to adjust or rewrite the one we are providing. But wait! Didn't we provide patches to Monocle for the missing instances for `ListMap`? Yes we did! So how about removing our custom instances?

```txt
[warn] 62 warnings found
[success] ...
```

Nice! Always remember: It pays off to provide your custom extensions and patches upstream!

However now we get a lot of errors if we try to compile our tests. So we need to investigate. But before we do that let's fix all these deprecation warnings to get our code clean. Some things are pretty trivial but if we remove the `possible` command which has no replacement then our code does not compile any longer. We could just ignore it because it is a warning but it is a deprecation one therefore it definitely *will* come back later to bite us. However we ignore it for now and look at our weird compile error in the tests.

```txt
[error] ... object scalatestplus is not a member of package org
```

This is strange not only because Monocle has no apparent connection to our testing libraries. But doing our research we find an issue in the bugtracker of scalatestplus[^42] and applying the workaround from there (manually including a dependency to discipline-scalatest) solves our issue. Hooray! But to be honest: I have no idea what is going on behind the scenes here. Likely some dependency issues which cannot be resolved and are silently dropped or so. While we're at it we simply upgrade our Scala version to 2.13.8.

Ignoring the remaining deprecation warnings our tests are running fine and we take another look at the output of `migrate-libs tapir` within sbt. It seems we have to at least upgrade to tapir 0.18.x. The current stable version being 0.19.x we can see that it depends on http4s 0.23.x which in turn depends on cats-effect 3. Being a major rewrite version 3 of cats-effect will clash with our doobie version. So we will have to switch to the current pre-release version of it. But at least it is close to being released. :-)

Because the dependencies are so much weaved together we have no choice but to update them all in one step. We won't have compiling code either way and will likely get misleading error messages if we do them step by step. So let's increase some version numbers, take a deep breath and parse some compiler errors. To summarise: We update doobie to 1.0.0-RC2, http4s to 0.23.10 and tapir to 0.19.4. Additionally we have to adjust the tapir swagger ui package because some packaging changed.

```txt
[warn] 5 warnings found
[error] 33 errors found
[error] (Compile / compileIncremental) Compilation failed
```

Okay, that doesn't look too bad. Remember, we fixed similar numbers already. But where to start?

One of the libraries in the background that all others are using is cats-effect so maybe we should start with that one. Reading the migration guide we realise that there is a Scalafix migration which we could use for automatic conversion of our code. But it says: "Remember to run it *before* making any changes to your dependencies' versions." ;-)

So then let us rollback our versions and take a stab at the migration to cats effect 3 via Scalafix. The guide to manually applying the migration is straightforward however the results are a bit underwhelming as nearly nothing is changed. But the migration guide has lots of additional information about changed type hierarchies and so on so we are not left in the dark. Therefore we re-apply our version upgrades again and go on fixing the compilation errors. For convenience we start at our main entry point which is in `Tapir.scala`.

Concentrating on cats-effect first we need to adjust our `IOApp.WithContext` into a simply `IOApp` and can remove some code which is not needed any longer. Afterwards we have fixed some errors and the ones that still show up seem to be related to tapir and http4s. On the http4s side it seems that we now need a proper `Host` class instead of our non-empty string. So one option would be do to something like this:

```scala
host <- IO(
  com.comcast.ip4s.Host
    .fromString(apiConfig.host)
    .getOrElse(throw new RuntimeException("Invalid hostname!"))
)
```

It will work but why do we have introduced properly typed configuration then? On the other hand we might have to drop pureconfig because the migrate plugin told us that there is no version of it for Scala 3 yet. However looking at the repository and bugtracker [^43]we can see that basic Scala 3 support is supposed to be there. So let's try to do it the proper way first!

While we're at it we realise that we also need a `Port` type also instead of custom `PortNumber` and of course pureconfig needs to be provided with type classes which can read these types.

```scala
import com.comcast.ip4s.{ Host, Port }
import pureconfig._
import pureconfig.generic.semiauto._

final case class ApiConfig(host: Host, port: Port)

object ApiConfig {
  implicit val hostReader: ConfigReader[Host] =
    ConfigReader.fromStringOpt[Host](Host.fromString)
  implicit val portReader: ConfigReader[Port] =
    ConfigReader.fromStringOpt[Port](Port.fromString)

  implicit val configReader: ConfigReader[ApiConfig] =
    deriveReader[ApiConfig]
}
```

This is our new `ApiConfig` class (comments removed from the snippet) and it looks like it works because we have even less compiler errors now. :-)

However there is a new one now for the last part of our for comprehension returning the `fiber`:

```txt
found   : cats.effect.IO[cats.effect.ExitCode]
required: cats.effect.ExitCode
```

This is fixed easily though by just changing the `fiber = ...` to `fiber <- ...` within the for comprehension. After that we take a look at the error we get from tapir. They are related to the swagger UI and API documentation stuff. Referring to the tapir documentation the changes are quite simple, we just change an import and the way we construct our documentation structure.

```scala
import sttp.tapir.swagger.SwaggerUI
//...
docs = OpenAPIDocsInterpreter().toOpenAPI(
  List(
    ProductRoutes.getProduct,
    ProductRoutes.updateProduct,
    ProductsRoutes.getProducts,
    ProductsRoutes.createProduct
  ),
  "Pure Tapir API",
  "1.0.0"
)
updatedDocs = updateDocumentation(docs)
docsRoutes  = Http4sServerInterpreter[IO]()
                .toRoutes(SwaggerUI[IO](updatedDocs.toYaml))
//...
httpApp     = Router("/" -> routes, "/docs" -> docsRoutes).orNotFound
```

Another step done, nice! Let's enjoy the moment and move on to the other errors which are in our optics part of the file where we define lenses on the `OpenAPI` structure of tapir which seems to have changed quite a lot. So for starters there is the `ReferenceOr` structure which simply moved to another place so we can just add an import and reference it directly instead of `OpenAPI.ReferenceOr` and some errors are gone. Others are about the internal structure for example we now get a `Paths` type instead of a `ListMap` on some attributes. But before we dive to deep into this one we might as well thing about refactoring our optics part a bit more because we basically kept our old approach and just changed it so far as to compile with the latest Monocle library. But what about actually utilising the shiny new features? ;-)

But let's save this for later because the really nice features are Scala 3 only. So we just stub our function out and make it simply return the parameter it receives to make it compile again.

```scala
private def updateDocumentation(docs: OpenAPI): OpenAPI = docs
```

Some of the errors left are related to tapir schemas so let's try them first because they are few and directly related to our data models. Instead of specifying everything manually we try the semi-automatic derivation this time. We soon realise that we still have to specify some instances but the code we need to make it compile looks cleaner than the one before:

```scala
object Translation {
  //...
  implicit val schemaForLanguageCode: Schema[LanguageCode] =
    Schema.string
  implicit val schemaForProductName: Schema[ProductName] =
    Schema.string
  implicit val schemaFor: Schema[Translation] =
    Schema.derived[Translation]
}
object Product {
  //...
  implicit val schemaForProductId: Schema[ProductId] = Schema.string

  implicit def schemaForNeS[T](implicit a: Schema[T]):
    Schema[NonEmptySet[T]] = Schema(SchemaType.SArray(a)(_.toIterable))

  implicit val schemaFor: Schema[Product] = Schema.derived[Product]
}
```

So far so good. If we really nailed it we will only know later when if may blow up in our faces or not. ;-)

Further on we need to replace the `Sync` type in our routing classes with `Async` to fix two more errors. The route creation changed so we have to use a `Http4sServerInterpreter[F]().toRoutes(...)` function now to create our routes. It still gives some errors but let's look at our endpoint definitions first. The type signature for endpoints changes from `[I, E, O, S]` to `[A, I, E, O, R]`. Sorry for the abbreviation overkill here. The details can be looked up at the tapir docs but the gist is that we have an additional type ("security input") at the start and instead of the "streaming type" we have a "capabilities type" now at the end. Because we don't use the security input type we can set it to `Unit` or could also use the `PublicEndpoint` type alias which is provided by tapir. In the case of streaming endpoints the output type stays as before (`Stream[F, Byte]`) and the capabilities type at the end becomes `Fs2Streams[F]` or `Any` for all non streaming endpoints.

For our streaming endpoint (`getProducts`) we get an error about the `streamBody` specification so we can adjust that one or replace it with the new `streamTextBody` directive. Both ways should work.

```scala
streamTextBody(Fs2Streams[F])(CodecFormat.Json(),
  Option(StandardCharsets.UTF_8))
```

We are down to a single digit number of compiler errors for our main code. This looks not bad so let's head on. The main issue now seems to stem from the `toRoutes` functionality.

```txt
[error] overloaded method toRoutes with alternatives:
[error]   (serverEndpoints: List[sttp.tapir.server.ServerEndpoint[
            sttp.capabilities.fs2.Fs2Streams[F],F]])
              org.http4s.HttpRoutes[F] <and>
[error]   (se: sttp.tapir.server.ServerEndpoint[
            sttp.capabilities.fs2.Fs2Streams[F],F])
              org.http4s.HttpRoutes[F]
[error]  cannot be applied to (sttp.tapir.Endpoint[
           Unit,ProductId,StatusCode,Product,Any])
[error]     Http4sServerInterpreter[F]().toRoutes(...) { id =>
[error]                                  ^
```

For me this looks like the function will only accept streaming endpoints which doesn't make sense and would have surely been mentioned in the documentation or some release notes of the tapir project. But we take a closer look and we see that it actually expects `ServerEndpoint` instances here, not `Endpoint` ones. Or to quote from the documentation:

*To interpret a single endpoint, or multiple endpoints as a server, the endpoint descriptions must be coupled with functions which implement the server logic. The shape of these functions must match the types of the inputs and outputs of the endpoint.*

So server logic is added to an endpoint via one of the functions starting with `serverLogic` of course. ;-)

For our purpose we will use the default one (simply `serverLogic`). Let's test it out on one route:

```scala
final class ProductRoutes[F[_]: Async] ... {
  //...
  private val getRoute: HttpRoutes[F] =
    Http4sServerInterpreter[F]().toRoutes(ProductRoutes.getProduct
      .serverLogic { id =>
        for {
          rows <- repo.loadProduct(id)
          resp = Product
            .fromDatabase(rows)
            .fold(StatusCode.NotFound.asLeft[Product])(_.asRight[StatusCode])
        } yield resp
      })

  private val updateRoute: HttpRoutes[F] =
    Http4sServerInterpreter[F]().toRoutes(ProductRoutes.updateProduct
      .serverLogic {
        case (_, p) =>
          for {
            cnt <- repo.updateProduct(p)
            res = cnt match {
              case 0 => StatusCode.NotFound.asLeft[Unit]
              case _ => ().asRight[StatusCode]
            }
          } yield res
      })
  //...
}
```

And it compiles fine! So we just need to move our logic into the `serverLogic` function part and we are set. Pretty cool but once we fix it we get another error from our main entry point:

```txt
Tapir.scala:42:26: method executionContextResource overrides nothing
```

However we can simply remove it and are done. Oh wait! We are skipped two things: first there is still the optics implementation left and second we want to fix this `example` problem in the one endpoint definition. Besides that we also get a lot of compilation errors for our tests. We turn there first an can very quickly fix our integration tests by removing the no longer used `IO.contextShift` from our `DoobieRepositoryTest` and by providing an implicit `IORuntime` within our `BaseSpec` class.

It turns out that for our regular tests we can apply the same fix to the `BaseSpec` there and also remove some obsolete code and adjust our imports because the http4s library has now a type called `ProductId` which clashes with our own one. After changing the `Effect` type in our `TestRepository` to `Async` the only thing left seems to be the ScalaCheck generators for our `ApiConfig` but these are also fixed easily.

So we fixed the compilation errors in our tests, but alas some tests are failing. :-(

At least the integration tests look fine, so let's take a look at the possible reasons for our failing tests. The failing ones are: `ApiConfigTest`, `ProductRoutesTest` and `ProductsRoutesTest`. The first one spills out the following message:

```txt
ApiConfig(127.0.0.1,34019) was not equal to ApiConfig(127.0.0.1,34019)
```

I don't know about you dear reader but I have stumbled into equality issues frequently (not *always* though but regular) so this should be resolvable by changing the `c must be(expected)` line in the test.

```scala
ConfigSource.fromConfig(config).at("api").load[ApiConfig] match {
  case Left(e)  => fail(s"Parsing a valid configuration must succeed! ($e)")
  case Right(c) => withClue("Config must be equal!")(c === expected)
}
```

In addition we add an implicit instance for the `Eq` of cats into the companion object of the `ApiConfig` class.

```scala
implicit val eqApiConfig: Eq[ApiConfig] = Eq.instance { (a, b) =>
  a.host === b.host && a.port === b.port
}
```

This fixes it and we can turn to the two remaining one. We soon find that the error message returned by tapir (which we check in the tests) has changed and is now more detailed so we simply adjust the according line in both tests and we are done here.

[^41]: https://github.com/optics-dev/Monocle/issues/1001

[^42]: https://github.com/scalatest/scalatestplus-scalacheck/issues/36

[^43]: https://github.com/pureconfig/pureconfig/issues/970

